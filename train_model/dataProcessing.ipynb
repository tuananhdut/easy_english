{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset, load_metric, Audio, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(timit_path + '/train_data.csv')\n",
    "df_test = pd.read_csv(timit_path +'/test_data.csv')\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = df[df['is_converted_audio'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.TXT</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.TXT</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8394</th>\n",
       "      <td>8395.0</td>\n",
       "      <td>TEST</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MPAM0</td>\n",
       "      <td>SX19.WAV</td>\n",
       "      <td>TEST/DR8/MPAM0/SX19.WAV</td>\n",
       "      <td>TEST\\\\DR8\\\\MPAM0\\\\SX19.WAV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>8396.0</td>\n",
       "      <td>TEST</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MPAM0</td>\n",
       "      <td>SX109.TXT</td>\n",
       "      <td>TEST/DR8/MPAM0/SX109.TXT</td>\n",
       "      <td>TEST\\\\DR8\\\\MPAM0\\\\SX109.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>8398.0</td>\n",
       "      <td>TEST</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MPAM0</td>\n",
       "      <td>SX289.WRD</td>\n",
       "      <td>TEST/DR8/MPAM0/SX289.WRD</td>\n",
       "      <td>TEST\\\\DR8\\\\MPAM0\\\\SX289.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>8399.0</td>\n",
       "      <td>TEST</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MPAM0</td>\n",
       "      <td>SX109.WAV</td>\n",
       "      <td>TEST/DR8/MPAM0/SX109.WAV</td>\n",
       "      <td>TEST\\\\DR8\\\\MPAM0\\\\SX109.WAV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>TEST</td>\n",
       "      <td>DR8</td>\n",
       "      <td>MPAM0</td>\n",
       "      <td>SX289.PHN</td>\n",
       "      <td>TEST/DR8/MPAM0/SX289.PHN</td>\n",
       "      <td>TEST\\\\DR8\\\\MPAM0\\\\SX289.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25200 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id    filename  \\\n",
       "1        2.0         TRAIN            DR4      MMDM0  SI1311.PHN   \n",
       "2        3.0         TRAIN            DR4      MMDM0  SI1311.WRD   \n",
       "3        4.0         TRAIN            DR4      MMDM0   SX321.PHN   \n",
       "4        5.0         TRAIN            DR4      MMDM0   SX321.WRD   \n",
       "5        6.0         TRAIN            DR4      MMDM0   SI681.TXT   \n",
       "...      ...           ...            ...        ...         ...   \n",
       "8394  8395.0          TEST            DR8      MPAM0    SX19.WAV   \n",
       "8395  8396.0          TEST            DR8      MPAM0   SX109.TXT   \n",
       "8397  8398.0          TEST            DR8      MPAM0   SX289.WRD   \n",
       "8398  8399.0          TEST            DR8      MPAM0   SX109.WAV   \n",
       "8399  8400.0          TEST            DR8      MPAM0   SX289.PHN   \n",
       "\n",
       "              path_from_data_dir     path_from_data_dir_windows  \\\n",
       "1     TRAIN/DR4/MMDM0/SI1311.PHN  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "2     TRAIN/DR4/MMDM0/SI1311.WRD  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "3      TRAIN/DR4/MMDM0/SX321.PHN   TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "4      TRAIN/DR4/MMDM0/SX321.WRD   TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "5      TRAIN/DR4/MMDM0/SI681.TXT   TRAIN\\\\DR4\\\\MMDM0\\\\SI681.TXT   \n",
       "...                          ...                            ...   \n",
       "8394     TEST/DR8/MPAM0/SX19.WAV     TEST\\\\DR8\\\\MPAM0\\\\SX19.WAV   \n",
       "8395    TEST/DR8/MPAM0/SX109.TXT    TEST\\\\DR8\\\\MPAM0\\\\SX109.TXT   \n",
       "8397    TEST/DR8/MPAM0/SX289.WRD    TEST\\\\DR8\\\\MPAM0\\\\SX289.WRD   \n",
       "8398    TEST/DR8/MPAM0/SX109.WAV    TEST\\\\DR8\\\\MPAM0\\\\SX109.WAV   \n",
       "8399    TEST/DR8/MPAM0/SX289.PHN    TEST\\\\DR8\\\\MPAM0\\\\SX289.PHN   \n",
       "\n",
       "     is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "1                 False    False        False             True   \n",
       "2                 False    False         True            False   \n",
       "3                 False    False        False             True   \n",
       "4                 False    False         True            False   \n",
       "5                 False    False        False            False   \n",
       "...                 ...      ...          ...              ...   \n",
       "8394              False     True        False            False   \n",
       "8395              False    False        False            False   \n",
       "8397              False    False         True            False   \n",
       "8398              False     True        False            False   \n",
       "8399              False    False        False             True   \n",
       "\n",
       "     is_sentence_file  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "5                True  \n",
       "...               ...  \n",
       "8394            False  \n",
       "8395             True  \n",
       "8397            False  \n",
       "8398            False  \n",
       "8399            False  \n",
       "\n",
       "[25200 rows x 12 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25200it [00:01, 24727.25it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    path = row['path_from_data_dir']\n",
    "    entry_id = path.split('.')[0]\n",
    "\n",
    "    if entry_id not in data:\n",
    "        data[entry_id] = {}\n",
    "\n",
    "    if row['is_audio'] is True:\n",
    "        data[entry_id]['audio_file'] = os.path.join(data_path, path)\n",
    "    elif row['is_word_file'] is True:\n",
    "        data[entry_id]['word_file'] = os.path.join(data_path, path)\n",
    "    elif row['is_phonetic_file'] is True:\n",
    "        data[entry_id]['phonetic_file'] = os.path.join(data_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "keys = [key for key in data.keys() if len(data[key]) == 3]\n",
    "random.Random(101).shuffle(keys)\n",
    "\n",
    "num_train = int(len(keys) * 0.8)\n",
    "num_valid = int(len(keys) * 0.1)\n",
    "num_test = len(keys) - num_train - num_valid\n",
    "\n",
    "train_keys = keys[:num_train]\n",
    "valid_keys = keys[num_train:num_train + num_valid]\n",
    "test_keys = keys[-num_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = { key:data[key] for key in train_keys }\n",
    "valid = { key:data[key] for key in valid_keys }\n",
    "test  = { key:data[key] for key in test_keys }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def get_durations(dict_data):\n",
    "    total_durations = 0\n",
    "\n",
    "    for entry in dict_data.values():\n",
    "        audio_data, _ = librosa.load(entry['audio_file'], sr=16_000)\n",
    "        duration = len(audio_data) / 16_000\n",
    "        total_durations += duration\n",
    "\n",
    "    return int(total_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Duration of Train: {get_durations(train) // 60} mns\")\n",
    "# print(f\"Duration of Valid: {get_durations(valid) // 60} mns\")\n",
    "# print(f\"Duration of Test : {get_durations(test) // 60} mns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/custom/custom_train.json\", \"w\") as f:\n",
    "    json.dump(train, f)\n",
    "with open(\"./data/custom/custom_valid.json\", \"w\") as f:\n",
    "    json.dump(valid, f)\n",
    "with open(\"./data/custom/custom_test.json\", \"w\") as f:\n",
    "    json.dump(test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_feature_dict(data_dict):\n",
    "    # convert each feature into an array instead\n",
    "    audio_files = []\n",
    "    word_files = []\n",
    "    phonetic_files = []\n",
    "    for key, value in data_dict.items():\n",
    "        audio_files.append(value['audio_file'])\n",
    "        word_files.append(value['word_file'])\n",
    "        phonetic_files.append(value['phonetic_file'])\n",
    "    \n",
    "    return {\n",
    "        'audio_file': audio_files,\n",
    "        'word_file': word_files,\n",
    "        'phonetic_file': phonetic_files\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = convert_to_feature_dict(train)\n",
    "valid = convert_to_feature_dict(valid)\n",
    "test  = convert_to_feature_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               audio_file  \\\n",
      "0      ./data/data/TEST/DR7/FISB0/SA1.WAV   \n",
      "1  ./data/data/TRAIN/DR4/MAEB0/SI1411.WAV   \n",
      "2    ./data/data/TRAIN/DR2/FCAJ0/SX39.WAV   \n",
      "3    ./data/data/TRAIN/DR3/MILB0/SX93.WAV   \n",
      "4   ./data/data/TEST/DR2/MMDM2/SI2082.WAV   \n",
      "\n",
      "                                word_file  \\\n",
      "0      ./data/data/TEST/DR7/FISB0/SA1.WRD   \n",
      "1  ./data/data/TRAIN/DR4/MAEB0/SI1411.WRD   \n",
      "2    ./data/data/TRAIN/DR2/FCAJ0/SX39.WRD   \n",
      "3    ./data/data/TRAIN/DR3/MILB0/SX93.WRD   \n",
      "4   ./data/data/TEST/DR2/MMDM2/SI2082.WRD   \n",
      "\n",
      "                            phonetic_file  \n",
      "0      ./data/data/TEST/DR7/FISB0/SA1.PHN  \n",
      "1  ./data/data/TRAIN/DR4/MAEB0/SI1411.PHN  \n",
      "2    ./data/data/TRAIN/DR2/FCAJ0/SX39.PHN  \n",
      "3    ./data/data/TRAIN/DR3/MILB0/SX93.PHN  \n",
      "4   ./data/data/TEST/DR2/MMDM2/SI2082.PHN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chuyển đổi dict thành DataFrame\n",
    "train_dataset = pd.DataFrame(train)\n",
    "valid_dataset    = pd.DataFrame(valid)\n",
    "test_dataset  = pd.DataFrame(test)\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(train_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  audio_file  \\\n",
      "0         ./data/data/TEST/DR7/FISB0/SA1.WAV   \n",
      "1     ./data/data/TRAIN/DR4/MAEB0/SI1411.WAV   \n",
      "2       ./data/data/TRAIN/DR2/FCAJ0/SX39.WAV   \n",
      "3       ./data/data/TRAIN/DR3/MILB0/SX93.WAV   \n",
      "4      ./data/data/TEST/DR2/MMDM2/SI2082.WAV   \n",
      "...                                      ...   \n",
      "2683    ./data/data/TEST/DR7/FCAU0/SX317.WAV   \n",
      "2684    ./data/data/TEST/DR7/MTWH0/SX290.WAV   \n",
      "2685   ./data/data/TRAIN/DR4/MRFL0/SX436.WAV   \n",
      "2686     ./data/data/TRAIN/DR3/FSKC0/SA2.WAV   \n",
      "2687    ./data/data/TEST/DR7/MKJL0/SX110.WAV   \n",
      "\n",
      "                                   word_file  \\\n",
      "0         ./data/data/TEST/DR7/FISB0/SA1.WRD   \n",
      "1     ./data/data/TRAIN/DR4/MAEB0/SI1411.WRD   \n",
      "2       ./data/data/TRAIN/DR2/FCAJ0/SX39.WRD   \n",
      "3       ./data/data/TRAIN/DR3/MILB0/SX93.WRD   \n",
      "4      ./data/data/TEST/DR2/MMDM2/SI2082.WRD   \n",
      "...                                      ...   \n",
      "2683    ./data/data/TEST/DR7/FCAU0/SX317.WRD   \n",
      "2684    ./data/data/TEST/DR7/MTWH0/SX290.WRD   \n",
      "2685   ./data/data/TRAIN/DR4/MRFL0/SX436.WRD   \n",
      "2686     ./data/data/TRAIN/DR3/FSKC0/SA2.WRD   \n",
      "2687    ./data/data/TEST/DR7/MKJL0/SX110.WRD   \n",
      "\n",
      "                               phonetic_file  \n",
      "0         ./data/data/TEST/DR7/FISB0/SA1.PHN  \n",
      "1     ./data/data/TRAIN/DR4/MAEB0/SI1411.PHN  \n",
      "2       ./data/data/TRAIN/DR2/FCAJ0/SX39.PHN  \n",
      "3       ./data/data/TRAIN/DR3/MILB0/SX93.PHN  \n",
      "4      ./data/data/TEST/DR2/MMDM2/SI2082.PHN  \n",
      "...                                      ...  \n",
      "2683    ./data/data/TEST/DR7/FCAU0/SX317.PHN  \n",
      "2684    ./data/data/TEST/DR7/MTWH0/SX290.PHN  \n",
      "2685   ./data/data/TRAIN/DR4/MRFL0/SX436.PHN  \n",
      "2686     ./data/data/TRAIN/DR3/FSKC0/SA2.PHN  \n",
      "2687    ./data/data/TEST/DR7/MKJL0/SX110.PHN  \n",
      "\n",
      "[2688 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        tokens = [line.split()[-1] for line in f]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "def prepare_text_data(item):\n",
    "    item['text'] = read_text_file(item['word_file'])\n",
    "    item['phonetic'] = read_text_file(item['phonetic_file'])\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               audio_file  \\\n",
      "0      ./data/data/TEST/DR7/FISB0/SA1.WAV   \n",
      "1  ./data/data/TRAIN/DR4/MAEB0/SI1411.WAV   \n",
      "2    ./data/data/TRAIN/DR2/FCAJ0/SX39.WAV   \n",
      "3    ./data/data/TRAIN/DR3/MILB0/SX93.WAV   \n",
      "4   ./data/data/TEST/DR2/MMDM2/SI2082.WAV   \n",
      "\n",
      "                                                text  \\\n",
      "0  she had your dark suit in greasy wash water al...   \n",
      "1  resolved that the anti slavery sentiment is be...   \n",
      "2      barb's gold bracelet was a graduation present   \n",
      "3                   cut a small corner off each edge   \n",
      "4                      you're boiling milk ain't you   \n",
      "\n",
      "                                            phonetic  \n",
      "0  h# sh iy hv ae dcl d y er dcl d aa r kcl k s u...  \n",
      "1  h# r ix z aa l v dh eh tcl dh iy ae nx ix s l ...  \n",
      "2  h# b aa r bcl b z gcl g ow l dcl b r ey s epi ...  \n",
      "3  h# k ah dx ax s epi m ao l kcl k ao r nx er ao...  \n",
      "4  h# y axr bcl b oy l ix ng m ih l kcl k q ey n ...  \n"
     ]
    }
   ],
   "source": [
    "# Áp dụng hàm xử lý `prepare_text_data` lên từng dòng\n",
    "train_dataset = train_dataset.apply(prepare_text_data, axis=1)\n",
    "valid_dataset = valid_dataset.apply(prepare_text_data, axis=1)\n",
    "test_dataset  = test_dataset.apply(prepare_text_data, axis=1)\n",
    "\n",
    "# Loại bỏ cột không cần thiết\n",
    "train_dataset = train_dataset.drop(columns=[\"word_file\", \"phonetic_file\"])\n",
    "valid_dataset = valid_dataset.drop(columns=[\"word_file\", \"phonetic_file\"])\n",
    "test_dataset  = test_dataset.drop(columns=[\"word_file\", \"phonetic_file\"])\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(train_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train phones:\t 61\n"
     ]
    }
   ],
   "source": [
    "# Lấy danh sách phonetics từ train_dataset\n",
    "train_phonetics = [phone for phonetic in train_dataset[\"phonetic\"] for phone in phonetic.split()]\n",
    "\n",
    "# Đếm số lượng phonemes khác nhau\n",
    "print(\"num of train phones:\\t\", len(set(train_phonetics)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimitBet 61 phoneme mapping to 39 phonemes\n",
    "# by Lee, K.-F., & Hon, H.-W. (1989). Speaker-independent phone recognition using hidden Markov models. IEEE Transactions on Acoustics, Speech, and Signal Processing, 37(11), 1641–1648. doi:10.1109/29.46546 \n",
    "phon61_map39 = {\n",
    "    'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n",
    "    'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n",
    "    'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n",
    "    'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n",
    "    'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n",
    "    'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n",
    "    'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n",
    "    'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#' \n",
    "}\n",
    "\n",
    "def convert_phon61_to_phon39(sentence):\n",
    "    tokens = [phon61_map39[x] for x in sentence.split()]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def normalize_phones(item):\n",
    "    item['phonetic'] = convert_phon61_to_phon39(item['phonetic'])\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_phones(phonetic_text):\n",
    "    return convert_phon61_to_phon39(phonetic_text)  # Chỉ nhận vào chuỗi và trả về chuỗi\n",
    "\n",
    "# Áp dụng cho từng dòng trong DataFrame\n",
    "train_dataset[\"phonetic\"] = train_dataset[\"phonetic\"].apply(normalize_phones)\n",
    "valid_dataset[\"phonetic\"] = valid_dataset[\"phonetic\"].apply(normalize_phones)\n",
    "test_dataset[\"phonetic\"] = test_dataset[\"phonetic\"].apply(normalize_phones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train phones:\t 39\n",
      "num of valid phones:\t 39\n",
      "num of test phones:\t 39\n"
     ]
    }
   ],
   "source": [
    "train_phonetics = [phone for phonetic in train_dataset[\"phonetic\"] for phone in phonetic.split()]\n",
    "valid_phonetics = [phone for phonetic in valid_dataset[\"phonetic\"] for phone in phonetic.split()]\n",
    "test_phonetics = [phone for phonetic in test_dataset[\"phonetic\"] for phone in phonetic.split()]\n",
    "\n",
    "print(\"num of train phones:\\t\", len(set(train_phonetics)))\n",
    "print(\"num of valid phones:\\t\", len(set(valid_phonetics)))\n",
    "print(\"num of test phones:\\t\", len(set(test_phonetics)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_vocabs = set(train_phonetics)\n",
    "phone_vocabs.remove('h#')\n",
    "phone_vocabs = sorted(phone_vocabs)\n",
    "\n",
    "def count_frequency(phonetics):\n",
    "    phone_counts = {phone: 0 for phone in phone_vocabs}\n",
    "    for phone in phonetics:\n",
    "        if phone in phone_vocabs:\n",
    "            phone_counts[phone] += 1\n",
    "    # eliminate h# for visualization purposes\n",
    "    return [phone_counts[phone] for phone in phone_vocabs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phone_counts = count_frequency(train_phonetics)\n",
    "valid_phone_counts = count_frequency(valid_phonetics)\n",
    "test_phone_counts  = count_frequency(test_phonetics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phone_ratio = [count / sum(train_phone_counts) for count in train_phone_counts]\n",
    "valid_phone_ratio = [count / sum(valid_phone_counts) for count in valid_phone_counts]\n",
    "test_phone_ratio  = [count / sum(test_phone_counts) for count in test_phone_counts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(25,10))\n",
    "\n",
    "# plt.bar(phone_vocabs, train_phone_ratio)\n",
    "# plt.bar(phone_vocabs, valid_phone_ratio, bottom=train_phone_ratio)\n",
    "# plt.bar(phone_vocabs, test_phone_ratio, bottom=[(x+y) for x,y in zip(train_phone_ratio, valid_phone_ratio)])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  she had your dark suit in greasy wash water al...   \n",
      "1  resolved that the anti slavery sentiment is be...   \n",
      "2      barb's gold bracelet was a graduation present   \n",
      "3                   cut a small corner off each edge   \n",
      "4                      you're boiling milk ain't you   \n",
      "\n",
      "                                            phonetic  \\\n",
      "0  h# sh iy hh ae h# d y er h# d aa r h# k s uw h...   \n",
      "1  h# r ih z aa l v dh eh h# dh iy ae n ih s l ey...   \n",
      "2  h# b aa r h# b z h# g ow l h# b r ey s h# l ih...   \n",
      "3  h# k ah dx ah s h# m aa l h# k aa r n er aa f ...   \n",
      "4  h# y er h# b oy l ih ng m ih l h# k h# ey n h#...   \n",
      "\n",
      "                                               audio  \n",
      "0  [-6.103515625e-05, 6.103515625e-05, 0.00012207...  \n",
      "1  [-9.1552734375e-05, 3.0517578125e-05, 0.000152...  \n",
      "2  [0.0, -6.103515625e-05, -0.0001220703125, -3.0...  \n",
      "3  [-9.1552734375e-05, 0.0, -6.103515625e-05, 9.1...  \n",
      "4  [3.0517578125e-05, 6.103515625e-05, 0.0, 0.0, ...  \n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm để tải tệp âm thanh và thay đổi sampling rate\n",
    "def load_audio(file_path, sampling_rate=16_000):\n",
    "    # Đọc tệp âm thanh với `soundfile`\n",
    "    audio, sr = sf.read(file_path)\n",
    "    \n",
    "    # Nếu sampling rate không khớp, thay đổi nó (sử dụng resampling)\n",
    "    if sr != sampling_rate:\n",
    "        import librosa\n",
    "        audio = librosa.resample(audio, sr, sampling_rate)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Áp dụng hàm lên cột `audio_file`\n",
    "train_dataset['audio'] = train_dataset['audio_file'].apply(lambda x: load_audio(x, 16000))\n",
    "valid_dataset['audio'] = valid_dataset['audio_file'].apply(lambda x: load_audio(x, 16000))\n",
    "test_dataset['audio'] = test_dataset['audio_file'].apply(lambda x: load_audio(x, 16000))\n",
    "\n",
    "# Xóa cột `audio_file` nếu không còn cần thiết\n",
    "train_dataset = train_dataset.drop(columns=[\"audio_file\"])\n",
    "valid_dataset = valid_dataset.drop(columns=[\"audio_file\"])\n",
    "test_dataset = test_dataset.drop(columns=[\"audio_file\"])\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(train_dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  she had your dark suit in greasy wash water al...   \n",
      "\n",
      "                                            phonetic  \\\n",
      "0  h# sh iy hh ae h# d y er h# d aa r h# k s uw h...   \n",
      "\n",
      "                                               audio  \n",
      "0  [-6.103515625e-05, 6.103515625e-05, 0.00012207...  \n"
     ]
    }
   ],
   "source": [
    "train_dataset_first_row = train_dataset.iloc[[0]]\n",
    "print(train_dataset_first_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display as ipd\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# rand_int = random.randint(0, len(train_dataset)-1)\n",
    "\n",
    "# print(\"Text:\", train_dataset[rand_int][\"text\"])\n",
    "# print(\"Phonetics:\", train_dataset[rand_int][\"phonetic\"])\n",
    "# print(\"Input array shape:\", train_dataset[rand_int][\"audio\"][\"array\"].shape)\n",
    "# print(\"Sampling rate:\", train_dataset[rand_int][\"audio\"][\"sampling_rate\"])\n",
    "# ipd.Audio(data=train_dataset[rand_int][\"audio\"][\"array\"], autoplay=False, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_train = list(set(train_phonetics)) + [' ']\n",
    "vocab_valid = list(set(valid_phonetics)) + [' ']\n",
    "vocab_test  = list(set(test_phonetics)) + [' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'aa': 1, 'ae': 2, 'ah': 3, 'aw': 4, 'ay': 5, 'b': 6, 'ch': 7, 'd': 8, 'dh': 9, 'dx': 10, 'eh': 11, 'er': 12, 'ey': 13, 'f': 14, 'g': 15, 'h#': 16, 'hh': 17, 'ih': 18, 'iy': 19, 'jh': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'ng': 25, 'ow': 26, 'oy': 27, 'p': 28, 'r': 29, 's': 30, 'sh': 31, 't': 32, 'th': 33, 'uh': 34, 'uw': 35, 'v': 36, 'w': 37, 'y': 38, 'z': 39}\n"
     ]
    }
   ],
   "source": [
    "vocab_list = list(set(vocab_train + vocab_valid + vocab_test))\n",
    "vocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}\n",
    "\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the space more intuitive to understand\n",
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vocab.json\n",
    "import json\n",
    "with open('./data/custom/vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {\"a\": \"ə\", \"ey\": \"eɪ\", \"aa\": \"ɑ\", \"ae\": \"æ\", \"ah\": \"ə\", \"ao\": \"ɔ\",\n",
    "           \"aw\": \"aʊ\", \"ay\": \"aɪ\", \"ch\": \"ʧ\", \"dh\": \"ð\", \"eh\": \"ɛ\", \"er\": \"ər\",\n",
    "           \"hh\": \"h\", \"ih\": \"ɪ\", \"jh\": \"ʤ\", \"ng\": \"ŋ\",  \"ow\": \"oʊ\", \"oy\": \"ɔɪ\",\n",
    "           \"sh\": \"ʃ\", \"th\": \"θ\", \"uh\": \"ʊ\", \"uw\": \"u\", \"zh\": \"ʒ\", \"iy\": \"i\", \"y\": \"j\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "from transformers import Wav2Vec2Processor\n",
    "from tokenizers.processors import TemplateProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"./data/custom/\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\", )  # './' load vocab.json in the current directory\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)  \n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not prepare the input for the Transformer model.\n",
    "# This will resample the data and convert the sentence into indices\n",
    "# Batch here is just for one entry (row)\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    \n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"phonetic\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[261]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train_dataset = train_dataset.map(prepare_dataset, remove_columns=train_dataset.column_names)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# valid_dataset = valid_dataset.map(prepare_dataset, remove_columns=valid_dataset.column_names)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# test_dataset = test_dataset.map(prepare_dataset, remove_columns=test_dataset.column_names)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_dataset = \u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m valid_dataset = valid_dataset.map(prepare_dataset)\n\u001b[32m      6\u001b[39m test_dataset = test_dataset.map(prepare_dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:10468\u001b[39m, in \u001b[36mDataFrame.map\u001b[39m\u001b[34m(self, func, na_action, **kwargs)\u001b[39m\n\u001b[32m  10465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(x):\n\u001b[32m  10466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x._map_values(func, na_action=na_action)\n\u001b[32m> \u001b[39m\u001b[32m10468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:10466\u001b[39m, in \u001b[36mDataFrame.map.<locals>.infer\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m  10465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(x):\n\u001b[32m> \u001b[39m\u001b[32m10466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\Desktop\\DATN\\SourceCode\\train_model\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[260]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mprepare_dataset\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_dataset\u001b[39m(batch):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     audio = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# batched output is \"un-batched\"\u001b[39;00m\n\u001b[32m      8\u001b[39m     batch[\u001b[33m\"\u001b[39m\u001b[33minput_values\u001b[39m\u001b[33m\"\u001b[39m] = processor(audio[\u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m], sampling_rate=audio[\u001b[33m\"\u001b[39m\u001b[33msampling_rate\u001b[39m\u001b[33m\"\u001b[39m]).input_values[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# train_dataset = train_dataset.map(prepare_dataset, remove_columns=train_dataset.column_names)\n",
    "# valid_dataset = valid_dataset.map(prepare_dataset, remove_columns=valid_dataset.column_names)\n",
    "# test_dataset = test_dataset.map(prepare_dataset, remove_columns=test_dataset.column_names)\n",
    "train_dataset = train_dataset.map(prepare_dataset)\n",
    "valid_dataset = valid_dataset.map(prepare_dataset)\n",
    "test_dataset = test_dataset.map(prepare_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
